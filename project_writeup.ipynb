{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e483b2a8-ccd0-4365-85c4-e68d9174f2ed",
   "metadata": {},
   "source": [
    "# Data Science Salary Estimator: Project Overview \n",
    "**Project Goal**:  Created a tool that estimates data science salaries based on some factors associated with the job: geography, job title, company size, industry, # of competitors etc.\n",
    "* Scraped 1000 job descriptions from glassdoor using python and selenium\n",
    "* Engineered features from the text of each job description to quantify the value companies put on Python, Excel, AWS, and Spark. \n",
    "* Optimized Linear, Lasso, and Random Forest Regressors using GridsearchCV to reach the best model. \n",
    "* Built a client facing API using Flask "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a4365f-cb1e-4949-9f55-5bb34af68508",
   "metadata": {},
   "source": [
    "## Project Steps\n",
    "1. Project Planning\n",
    "2. Data Collection\n",
    "3. Data Cleaning\n",
    "4. Exploratory Data Analysis\n",
    "5. Model Building\n",
    "6. Production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3652e2af-658e-4771-b43b-497df8dd43db",
   "metadata": {},
   "source": [
    "## Code and Resources Used  \n",
    "**Python Version:** 3.7   \n",
    "**Packages:** pandas, numpy, sklearn, matplotlib, seaborn, selenium, flask, json, pickle  \n",
    "**Spyder IDE**  \n",
    "**Jupyter Notebooks**  \n",
    "**GridsearchCV**    \n",
    "**For Web Framework Requirements:**  `pip install -r requirements.txt`  \n",
    "**Scraper Github:** https://github.com/arapfaik/scraping-glassdoor-selenium  \n",
    "**Scraper Article:** https://towardsdatascience.com/selenium-tutorial-scraping-glassdoor-com-in-10-minutes-3d0915c905  \n",
    "**Flask Productionization:** https://towardsdatascience.com/productionize-a-machine-learning-model-with-flask-and-heroku-8201260503d2="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3506f8b-dd64-4e21-8e8e-187254d85744",
   "metadata": {},
   "source": [
    "## YouTube Project Walk-Through\n",
    "https://www.youtube.com/playlist?list=PL2zq7klxX5ASFejJj80ob9ZAnBHdz5O1t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e5242-1f50-4323-8f78-3fa85a46bfb5",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "Tweaked the web scraper github repo (above) to scrape 1000 job postings from glassdoor.com. With each job posting, I got the following:\n",
    "\n",
    "* Job Title\n",
    "* Salary Estimate\n",
    "* Job Description\n",
    "* Rating\n",
    "* Company\n",
    "* Location\n",
    "* Company Headquarters\n",
    "* Company Size\n",
    "* Company Founded Date\n",
    "* Type of Ownership\n",
    "* Industry\n",
    "* Sector\n",
    "* Revenue  \n",
    "* Competitors  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f392ce8a-8bc3-49e8-8db5-1dedf9375446",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "After scraping the data, I needed to clean it up so that it was usable for our model. I made the following changes and created the following variables:\n",
    "\n",
    "*\tParsed numeric data out of salary \n",
    "*\tMade columns for employer provided salary and hourly wages \n",
    "*\tRemoved rows from data set where salary was not listed \n",
    "*\tParsed rating out of company text \n",
    "*\tMade a new column for company state \n",
    "*\tAdded a column to indicate if the job was at the companyâ€™s headquarters \n",
    "*\tTransformed 'founded date' columnn into 'age of company' \n",
    "*\tMade columns to show if different skills were listed in the job dsescription:\n",
    "    * Python  \n",
    "    * R  \n",
    "    * Excel  \n",
    "    * AWS  \n",
    "    * Spark \n",
    "*\tAdded column for simplified job title and seniority level \n",
    "*\tColumn for job description length "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222048b8-10ac-48be-b668-32a846534b05",
   "metadata": {},
   "source": [
    "## EDA (Exploratory Data Analysis)\n",
    "I looked at the distributions of the data and the value counts for the various categorical variables. Below are a few highlights from the pivot tables.\n",
    "\n",
    "![Alt text]()\n",
    "![Alt text]()\n",
    "![Alt text]()\n",
    "![Alt text]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f60db0-b64b-4cb1-b502-9b3bab17e4f8",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "First, I transformed the categorical variables into dummy variables. I also split the data into train and test sets with a test size of 20%.\n",
    "\n",
    "I tried three different models and evaluated them using Mean Absolute Error (the average variance between actual values and projected values in the dataset). I chose MAE because it is relatively easy to interpret and the outliers weren't particularly bad for this type of model.\n",
    "\n",
    "I tried three different models:\n",
    "*    **Multiple Linear Regression** - Used as the baseline for my model.\n",
    "*    **Lasso Regression** - Because of the sparse data from the many categorical variables, I thought a normalized regression would be effective.\n",
    "*    **Random Forest** - Again, with the sparsity of the available data, I thought that this would be a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9aef12-a212-4da5-9b93-64b2329e3b3e",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "The Random Forest model far outperformed the other approaches on the test and validation sets.\n",
    "*    **Random Forest** : MAE = 11.22\n",
    "*    **Linear Regression** : MAE = 18.86\n",
    "*    **Ridge Regression** : MAE = 19.67"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e674681-3342-4e64-9b25-ea438be1bcbd",
   "metadata": {},
   "source": [
    "## Productionization\n",
    "In this step, I built a Flask API endpoint that was hosted on a local webserver by following along with the TDS tutorial in the reference section above. The API endpoint takes in a request with a list of values from a job posting and returns an estimated salary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
